# **📅 Generative AI Full 6-Week Daily Plan**

---

## **Week 1 – Foundations & Setup**

**Day 1 – Introduction & Lab Setup**

* 3–4 PM: What is GenAI, types (text, image, audio, video), key terms
* 8–9 PM: Install Python, VS Code, virtual environment, libraries (`openai`, `requests`, `python-dotenv`)
* Mini-task: Test first AI prompt (motivational quote)

**Day 2 – OpenAI API Basics**

* 3–4 PM: First Python script with OpenAI, system vs user messages
* 4–5 PM: Test multiple prompts, observe output differences
* 8–9 PM: Save scripts in project folder, organize workspace

**Day 3 – Prompt Engineering Intro**

* 3–4 PM: Role-based prompts, zero-shot & few-shot prompts
* 4–5 PM: Experiment with changing system role (“teacher”, “pirate”, “motivational coach”)
* 8–9 PM: Mini-task: AI storyteller script

**Day 4 – Image Generation Basics**

* 3–4 PM: DALL·E or Stable Diffusion introduction
* 4–5 PM: Generate simple images with text prompts
* 8–9 PM: Mini-task: Create 3 themed images

**Day 5 – Audio Basics (Optional)**

* 3–4 PM: TTS using ElevenLabs or OpenAI TTS
* 4–5 PM: STT using Whisper
* 8–9 PM: Mini-task: Convert AI text to speech

**Day 6 – Fun AI Assistant Mini-Project**

* 3–5 PM: Build a small AI assistant combining text & image outputs
* 8–9 PM: Test & refine prompts

**Day 7 – Week 1 Review & Practice**

* 3–5 PM: Revise all Week 1 concepts
* 8–9 PM: Try 3–5 new prompts for text, image, and audio

---

## **Week 2 – Advanced Prompt Engineering & Creative Output**

**Day 8 – Chain-of-Thought Prompts**

* 3–4 PM: Learn reasoning prompts
* 4–5 PM: Test step-by-step problem solving
* 8–9 PM: Mini-task: AI solves coding or logic puzzles

**Day 9 – Multi-turn Conversations**

* 3–4 PM: Store conversation history in Python
* 4–5 PM: Build simple chatbot memory
* 8–9 PM: Test conversations with multiple turns

**Day 10 – Formatting Outputs**

* 3–4 PM: Force AI to output JSON, lists, or tables
* 4–5 PM: Parse AI output in Python
* 8–9 PM: Mini-task: AI returns structured quiz questions

**Day 11 – Advanced Image Prompting**

* 3–4 PM: Control style, color, composition
* 4–5 PM: Try different image models
* 8–9 PM: Mini-task: Generate 3 creative posters

**Day 12 – Creative Text Projects**

* 3–4 PM: AI storytelling, poetry, jokes
* 4–5 PM: Experiment with tone & personality
* 8–9 PM: Mini-task: Generate a story + image for it

**Day 13 – Text + Image Combined Projects**

* 3–4 PM: Create multi-modal prompts
* 4–5 PM: Connect text story → AI-generated images
* 8–9 PM: Mini-task: Build a small “storybook AI”

**Day 14 – Week 2 Mini Project**

* 3–5 PM: **AI Study Buddy**: Chatbot + image generator for learning
* 8–9 PM: Test & refine outputs

---

## **Week 3 – AI App Development & Memory**

**Day 15 – LangChain Basics**

* 3–4 PM: Chains, memory, tools
* 4–5 PM: Connect OpenAI API
* 8–9 PM: Simple chatbot with memory

**Day 16 – LangChain Continued**

* 3–4 PM: Add document input (PDF, TXT)
* 4–5 PM: Query documents
* 8–9 PM: Mini-task: Ask AI questions about uploaded PDFs

**Day 17 – LlamaIndex Basics**

* 3–4 PM: Create document index
* 4–5 PM: Query your knowledge base
* 8–9 PM: Test multiple document types

**Day 18 – LlamaIndex Advanced**

* 3–4 PM: Add memory + indexing
* 4–5 PM: Test search & retrieval accuracy
* 8–9 PM: Mini-project: Chat with your notes

**Day 19 – Fun Applications**

* 3–5 PM: Build AI chatbot for study, coding help, or storytelling
* 8–9 PM: Refine prompts & responses

**Day 20 – Integration Practice**

* 3–5 PM: Combine LangChain + LlamaIndex
* 8–9 PM: Test multi-document Q\&A chatbot

**Day 21 – Week 3 Mini Project**

* 3–5 PM: Build **Personal AI Knowledge Base**
* 8–9 PM: Test conversation + document query

---

## **Week 4 – Deployment & Real-World Apps**

**Day 22 – FastAPI Basics**

* 3–4 PM: Routes, JSON response, connect OpenAI API
* 4–5 PM: Test simple endpoint returning AI-generated text
* 8–9 PM: Mini-task: Build “AI quote API”

**Day 23 – FastAPI + Images**

* 3–5 PM: Return image URLs or base64 from API
* 8–9 PM: Test multiple prompts

**Day 24 – Streamlit Frontend**

* 3–4 PM: Simple web interface
* 4–5 PM: Display AI-generated text + images
* 8–9 PM: Mini-task: Connect chatbot to web page

**Day 25 – Streamlit Continued**

* 3–5 PM: Improve UI, add multiple pages or tabs
* 8–9 PM: Test and refine

**Day 26 – Deployment Prep**

* 3–4 PM: Check requirements, virtual environment
* 4–5 PM: Prepare for deployment
* 8–9 PM: Test locally

**Day 27 – Deployment**

* 3–5 PM: Deploy on Render / Railway / Hugging Face Spaces
* 8–9 PM: Test live app

**Day 28 – Final Project**

* 3–5 PM: Choose: AI Resume Builder / Travel Planner / Blog Writer + Image
* 8–9 PM: Deploy & save code to GitHub

---

## **Weeks 5–6 – Mastery & Portfolio Expansion**

* Build multi-modal AI apps (text + image + audio)
* Experiment with LoRA fine-tuning (low-code)
* Build bots: Discord, Telegram, Notion AI
* Improve deployed apps: add memory, logging, analytics
* Publish 2–3 portfolio-ready projects

---

✅ **By the end of this roadmap**, you will be able to:

* Talk to AI models confidently
* Control AI outputs with advanced prompts
* Build chatbots, document Q\&A systems, and multi-modal apps
* Deploy AI applications online
* Create a strong AI project portfolio

